<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>


<configuration>
    <property>
     <!-- 查询数据时 显示出列的名字 -->
        <name>hive.cli.print.header</name>
        <value>true</value>
    </property>
    <property>
     <!-- 在命令行中显示当前所使用的数据库 -->
        <name>hive.cli.print.current.db</name>
        <value>true</value>
    </property>
    <property>
     <!-- 默认数据仓库存储的位置，该位置为HDFS上的路径 -->
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
    </property>
    <!-- 8.x -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:mysql://10.2.11.203:3306/metastore2?createDatabaseIfNotExist=true&amp;useSSL=false&amp;serverTimezone=GMT</value>
    </property>
    <!-- 8.x -->
    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>com.mysql.jdbc.Driver</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>root</value>
    </property>
    <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>123456</value>
    </property>
    
    <!-- <property> -->
        <!-- <name>hive.execution.engine</name> -->
        <!-- <value>mr</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>hive.enable.spark.execution.engine</name> -->
        <!-- <value>true</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.home</name> -->
        <!-- <value>/usr/local/soft/spark-2.4.8</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.master</name> -->
        <!-- <value>yarn</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.eventLog.enabled</name> -->
        <!-- <value>true</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.eventLog.dir</name> -->
        <!-- <value>hdfs://masters/spark-hive-jobhistory</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.executor.memory</name> -->
        <!-- <value>2048m</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.driver.memory</name> -->
        <!-- <value>1024m</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.serializer</name> -->
        <!-- <value>org.apache.spark.serializer.KryoSerializer</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>spark.yarn.jars</name> -->
        <!-- <value>hdfs://masters/spark-jars/*</value> -->
    <!-- </property> -->
    <!-- <property> -->
        <!-- <name>hive.spark.client.server.connect.timeout</name> -->
        <!-- <value>300000</value> -->
    <!-- </property> -->
</configuration>